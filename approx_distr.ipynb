{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = sp.distributions.norm(loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = normal.rvs(10)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for light tailed distr\n",
    "from typing import Tuple\n",
    "SMALL_VALUE: int = - 1e4\n",
    "LARGE_VALUE: int = 1e4\n",
    "\n",
    "def sign(x): return 1 if x >= 0 else -1\n",
    "\n",
    "def interpolate(x_min, x_max, n) -> list:\n",
    "    return np.linspace(x_min, x_max, n).tolist()\n",
    "\n",
    "def find_min_max(distr, thresh: float) -> Tuple[float, float]:\n",
    "    bd = (LARGE_VALUE + SMALL_VALUE) / 2\n",
    "    found_min = False\n",
    "    found_max = False\n",
    "    x_min = None\n",
    "    x_max = None\n",
    "\n",
    "    while not (found_min):\n",
    "\n",
    "        print(bd)\n",
    "        if abs(distr(bd) - thresh) < 1e-5: \n",
    "            x_min = bd\n",
    "            found_min = True\n",
    "        else:\n",
    "            # too far away -> adjust\n",
    "            bd += (distr(bd) - thresh) * (bd + SMALL_VALUE)\n",
    "        \n",
    "    # reset, start search again for max val\n",
    "    bd = (LARGE_VALUE + SMALL_VALUE) / 2\n",
    "    while not (found_max):\n",
    "        print(bd)\n",
    "        if abs(distr(bd) - (1 - thresh)) < 1e-5: \n",
    "            x_max = bd\n",
    "            found_max = True\n",
    "        else:\n",
    "            bd -= (distr(bd) - (1-thresh)) * (bd + LARGE_VALUE)\n",
    "    return x_min, x_max\n",
    "    \n",
    "\n",
    "def approx(n: int, distr: callable):\n",
    "    # x_min, x_max = find_min_max(distr)\n",
    "    x_min, x_max = -20, 20\n",
    "    # interpolate\n",
    "    xs = interpolate(x_min, x_max, n)\n",
    "    shift_left = [SMALL_VALUE]\n",
    "    shift_left.extend(xs)\n",
    "    xs.extend([LARGE_VALUE])\n",
    "    \n",
    "\n",
    "    # determine weights for bins\n",
    "    bins = [(x, y) for x,y in zip(shift_left, xs)]\n",
    "    mid_points = [b[1] - b[0] for b in bins]\n",
    "    probs = [(distr(b[1]) - distr(b[0])) for b in bins]\n",
    "    return probs \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal.cdf(-20)\n",
    "# find_min_max(normal.cdf, 0.05)\n",
    "temp = approx(100, normal.cdf)\n",
    "# ls = interpolate(-20,20,10)\n",
    "np.sum(temp)\n",
    "np.count_nonzero(np.where(np.asarray(temp) >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In theory, this works, needs work for find_min_max in a reliable way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is the implementation of the projection in case only a CDF of the reward distribution is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeAlias\n",
    "Distribution: TypeAlias = Tuple[np.ndarray, np.ndarray]\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "class Direction(Enum):\n",
    "    LEFT = 0 \n",
    "    RIGHT = 1\n",
    "\n",
    "\n",
    "class ProbMesh:\n",
    "    def __init__(self, atoms: np.ndarray, probs: np.ndarray):\n",
    "        self.atoms = atoms\n",
    "        self.probs = probs\n",
    "        self._sup_dist = self._sup_dist()\n",
    "\n",
    "    def _sort(self):\n",
    "        idcs: np.ndarray = np.argsort(self.atoms)\n",
    "        self.atoms = self.atoms[idcs]\n",
    "        self.probs = self.probs[idcs]\n",
    "\n",
    "    def _sup_dist(self):\n",
    "        sup_dist = np.max(np.diff(self.atoms, 1))\n",
    "        return sup_dist\n",
    "\n",
    "    def get_sup_dist(self): return self.sup_dist\n",
    "\n",
    "\n",
    "def algo_cdf(prior_distr: Distribution, k: int) -> Tuple[np.ndarray, ...]:\n",
    "    \"\"\"Assume that atoms in increasing order.\"\"\"\n",
    "\n",
    "    min_thresh = 5 * np.exp(-(k+5))\n",
    "    max_thresh = 1 - min_thresh\n",
    "    inter_thresh = min_thresh\n",
    "    # probably make this fixed e.g. 2^(k+1) atoms in k-th iteration\n",
    "    # print(\"Treshholds: \", end=\"\")\n",
    "    # print(min_thresh, max_thresh, inter_thresh)\n",
    "\n",
    "    v_min, p_min = prior_distr[0][0], prior_distr[1][0]\n",
    "    v_max, p_max = prior_distr[0][-1], prior_distr[1][-1]\n",
    "    left_extend = np.array([])\n",
    "    right_extend = np.array([])\n",
    "    mid_extend = np.array([])\n",
    "\n",
    "    if prior_distr[1][0] > min_thresh:\n",
    "        # extend to left\n",
    "        left_extend = extend_support(v_min, v_max, k, Direction.LEFT)\n",
    "\n",
    "    if (1 - prior_distr[1][-1]) > min_thresh:\n",
    "        # extend to right\n",
    "        right_extend = extend_support(v_min, v_max, k, Direction.RIGHT)\n",
    "\n",
    "    emp_cdf = np.cumsum(prior_distr[1])\n",
    "    if np.max(np.diff(emp_cdf, 1)) > inter_thresh:\n",
    "        mid_extend = interpolate_atoms(prior_distr, k)\n",
    "        # extend in the 'center'\n",
    "        pass\n",
    "\n",
    "\n",
    "    return left_extend, mid_extend, right_extend, prior_distr[0]\n",
    "\n",
    "def extend_support(v_min: float, v_max: float,  k: int, direction: Direction) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Extend support, returning more points to the left and more points to the right\"\"\"\n",
    "    # k >= 2 assumed\n",
    "    no_new_points: int = k // 2 \n",
    "    step_size = ( v_max - v_min ) * k\n",
    "    # print(f\"No of new points and step size: {no_new_points, step_size}\")\n",
    "\n",
    "    if direction == Direction.LEFT:\n",
    "        new_points = [v_min - step_size * (i+1) for i in range(no_new_points)]\n",
    "    elif direction == Direction.RIGHT:\n",
    "        new_points = [v_max + step_size * (i+1) for i in range(no_new_points)]\n",
    "\n",
    "    else:\n",
    "        # print(\"No valid direction\")\n",
    "        pass\n",
    "    return np.asarray(new_points)\n",
    "\n",
    "\n",
    "def interpolate_atoms(prior_distr: Distribution, k: int) -> np.ndarray:\n",
    "    \"\"\"Let mesh -> 0 over time, adding more points to eval cdf at.\"\"\"\n",
    "\n",
    "    # assume k >= 2\n",
    "    # assume atoms already in increasing order\n",
    "    atoms = prior_distr[0]\n",
    "    probs= prior_distr[1]\n",
    "    no_new_particles: int = k // 2\n",
    "    emp_cdf = np.cumsum(probs)\n",
    "    emp_cdf_diff = np.diff(emp_cdf, 1)\n",
    "    interpolation_order = np.argsort(emp_cdf_diff)[::-1]  # largest gap first\n",
    "    # print(\"Emp cdf, diff\", end=\"\")\n",
    "    # print(emp_cdf, emp_cdf_diff)\n",
    "\n",
    "    new_particles = atoms[interpolation_order[:no_new_particles] + 1] + \\\n",
    "                          atoms[interpolation_order[:no_new_particles]]\n",
    "    new_particles = new_particles / 2\n",
    "\n",
    "    # print(f\"new_particles: {new_particles}\")\n",
    "    # new_particles = [(atoms[interpolation_order[i]] - atoms[interpolation_order[i] - 1])/2\n",
    "                     # for i in range(no_new_particles)]\n",
    "    return new_particles\n",
    "\n",
    "\n",
    "\n",
    "def project_cdf(distr_cdf: callable, param: Tuple[np.ndarray, ...]) -> Distribution:\n",
    "    \"\"\"Project with new parameter.\n",
    "    \n",
    "    Given left, right, and mid extend from algo_cdf, eval cdf at new points.\n",
    "    Calc bins.\n",
    "    \"\"\"\n",
    "\n",
    "    ARBITRARY = 100\n",
    "    left, mid, right, prior_atoms = param\n",
    "    mid_joined = np.concatenate([mid, prior_atoms])\n",
    "    mid_joined = mid_joined[np.argsort(mid_joined)]\n",
    "    new_atoms = np.concatenate([left, mid_joined, right])\n",
    "    # print(f\"New atoms: {new_atoms}\")\n",
    "    \n",
    "    new_midpoints = (new_atoms[1:] + new_atoms[:-1]) / 2\n",
    "    # print(f\"New midpoints: {new_midpoints}\")\n",
    "    cdf_evals = distr_cdf(new_midpoints)\n",
    "\n",
    "    # print(f\"cdf evals: {cdf_evals}\")\n",
    "    new_probs = np.concatenate([cdf_evals[0:1], np.ediff1d(cdf_evals)])\n",
    "    \n",
    "    # print(f'new probs: {new_probs}')\n",
    "    new_probs[-1] += (1 - np.sum(new_probs))\n",
    "    # print(f\"cum sum of probs: {np.sum(new_probs)}\")\n",
    "    assert np.isclose(np.sum(new_probs), 1) == True\n",
    "    return (new_midpoints, new_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(-10, 10, 5)\n",
    "a\n",
    "\n",
    "a = a[np.argsort(a)]\n",
    "b = (a[1: ] + a[:-1]) / 2\n",
    "a,b\n",
    "\n",
    "a, np.ediff1d(a)\n",
    "\n",
    "a, np.concatenate([a[0:1], np.ediff1d(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(2)\n",
    "b = np.random.rand(2)\n",
    "a, b\n",
    "np.concatenate([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = np.random.randint(0,20, 5)\n",
    "atoms = atoms[np.argsort(atoms)]\n",
    "probs = np.random.rand(5)\n",
    "probs = probs / np.sum(probs)\n",
    "list(zip(atoms, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (atoms, probs)\n",
    "interpolate_atoms(d, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_support(atoms[0], atoms[-1], 2, Direction.LEFT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b = np.random.rand(5)\n",
    "atoms = np.random.randint(0, 10, size=5)\n",
    "probs = b / np.sum(b)\n",
    "\n",
    "cs = np.cumsum(probs)\n",
    "print(cs)\n",
    "d_of_cs = np.diff(cs)\n",
    "print(d_of_cs)\n",
    "order = np.argsort(d_of_cs)[::-1]\n",
    "print(np.argsort(d_of_cs)[::-1])\n",
    "\n",
    "\n",
    "# np.sum(b / np.sum(b))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(atoms[order] - atoms[order-1]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms[order-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "algo_cdf((atoms, probs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dist = (np.array([-10, 10]), np.array([.5, .5]))\n",
    "for k in range(2, 20):\n",
    "    param = algo_cdf(approx_dist, k)\n",
    "    # approx_dist = project_cdf(norm.cdf, param)\n",
    "    approx_dist = project_cdf(cauchy.cdf, param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(approx_dist[1]), len(approx_dist[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = sp.norm(loc = 0, scale=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchy = sp.cauchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lins = np.linspace(-100, 100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = cauchy\n",
    "# or distr = norm\n",
    "plt.plot(lins, distr.cdf(lins))\n",
    "plt.xlim(-20, 20)\n",
    "plt.plot(approx_dist[0], np.cumsum(approx_dist[1]))\n",
    "left, right = plt.xlim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis-5DTlbad3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
